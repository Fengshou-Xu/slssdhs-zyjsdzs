{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPeulvp-meob"
   },
   "source": [
    "**ASSIGNMENT 1 - EMPIRICAL STUDY OF KNAPSACK PROBLEM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2Eeke4Z_EkW"
   },
   "source": [
    "**1. Group Description**\n",
    "\n",
    "Group Number: \\\\\n",
    "Member Names: \\\\\n",
    "Member Student Numbers: \\\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yq6OGiMX_da0"
   },
   "source": [
    "**2. Knapsack Problem**\n",
    "\n",
    "Give a description of the problem tackled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8vwHE0G_iOG"
   },
   "source": [
    "**3. Dataset**\n",
    "\n",
    "Give a description of the dataset used with references.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZTWy1qN2BzY"
   },
   "source": [
    "**Import important libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "GmP1buROhaOx"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import numpy as np\n",
    "import itertools\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNJyoeCz00Kr"
   },
   "source": [
    "**Read Dataset**\n",
    "\n",
    "As outlined in the project description, it should be possible for the correctors to execute your notebook without requiring any downloads.\n",
    "\n",
    "To facilitate access to the dataset without the need for downloads, you can upload it to a public GitHub repository and provide a link to the raw version of the dataset.\n",
    "\n",
    "The link to the raw version is as follows:\n",
    "*https://raw.githubusercontent.com/GITHUB_USERNAME/REPOSITORY_NAME/main/DATASETNAME.csv*\n",
    "\n",
    "For example:\n",
    "\n",
    "https://raw.githubusercontent.com/baharin/KnapsackProblem/main/knapsack_5_items.csv\n",
    "\n",
    "Now provide the link to YOUR dataset and read the dataset using pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "BrhpM-HwhaOy"
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/Fengshou-Xu/slssdhs-zyjsdzs/main/knapsack_5_items.csv\"\n",
    "\n",
    "dataset = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Drc71BY2a7w"
   },
   "source": [
    "Let's see what are the columns of the dataset? :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pGxZXmhNhaOz",
    "outputId": "09bb8058-957c-4aae-fe50-de83e5a3b424"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Weights', 'Prices', 'Capacity', 'Best picks', 'Best price'], dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNZaqcCT2w-T"
   },
   "source": [
    "As we expected, we have columns for weights, costs, capacity, best picks and best price for all the instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jkokOHRj2kgZ"
   },
   "source": [
    "Now let's see the first 10 entries (rows):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "0xqfPrBEhaOz",
    "outputId": "4376de03-1214-492f-ba5e-304f9f0f1129"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weights</th>\n",
       "      <th>Prices</th>\n",
       "      <th>Capacity</th>\n",
       "      <th>Best picks</th>\n",
       "      <th>Best price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[46 40 42 38 10]</td>\n",
       "      <td>[12 19 19 15  8]</td>\n",
       "      <td>40</td>\n",
       "      <td>[0. 1. 0. 0. 0.]</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[11 31  4  6  7]</td>\n",
       "      <td>[ 2  8 18 16  3]</td>\n",
       "      <td>64</td>\n",
       "      <td>[1. 1. 1. 1. 1.]</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[32 49 27 37 24]</td>\n",
       "      <td>[19 16 16  4  1]</td>\n",
       "      <td>87</td>\n",
       "      <td>[1. 0. 1. 0. 1.]</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[20 35 22 23 16]</td>\n",
       "      <td>[19 17 19  9  1]</td>\n",
       "      <td>21</td>\n",
       "      <td>[1. 0. 0. 0. 0.]</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ 7 12 19 13 20]</td>\n",
       "      <td>[10 11 18 15  5]</td>\n",
       "      <td>50</td>\n",
       "      <td>[0. 1. 1. 1. 0.]</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[27 10 25 25  7]</td>\n",
       "      <td>[13 19  7 16  3]</td>\n",
       "      <td>66</td>\n",
       "      <td>[1. 1. 0. 1. 0.]</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[21  2 33 45 26]</td>\n",
       "      <td>[ 1 14 10  6 13]</td>\n",
       "      <td>80</td>\n",
       "      <td>[0. 1. 1. 0. 1.]</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[37 27 39 14 25]</td>\n",
       "      <td>[18  7 15  4 13]</td>\n",
       "      <td>35</td>\n",
       "      <td>[0. 0. 0. 0. 1.]</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[ 1 48  4 23 39]</td>\n",
       "      <td>[ 9  4 10 16 12]</td>\n",
       "      <td>51</td>\n",
       "      <td>[1. 0. 1. 1. 0.]</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[ 4  3 22  9 32]</td>\n",
       "      <td>[14  6  3 17  8]</td>\n",
       "      <td>53</td>\n",
       "      <td>[1. 1. 0. 1. 1.]</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Weights            Prices  Capacity        Best picks  Best price\n",
       "0  [46 40 42 38 10]  [12 19 19 15  8]        40  [0. 1. 0. 0. 0.]        19.0\n",
       "1  [11 31  4  6  7]  [ 2  8 18 16  3]        64  [1. 1. 1. 1. 1.]        47.0\n",
       "2  [32 49 27 37 24]  [19 16 16  4  1]        87  [1. 0. 1. 0. 1.]        36.0\n",
       "3  [20 35 22 23 16]  [19 17 19  9  1]        21  [1. 0. 0. 0. 0.]        19.0\n",
       "4  [ 7 12 19 13 20]  [10 11 18 15  5]        50  [0. 1. 1. 1. 0.]        44.0\n",
       "5  [27 10 25 25  7]  [13 19  7 16  3]        66  [1. 1. 0. 1. 0.]        48.0\n",
       "6  [21  2 33 45 26]  [ 1 14 10  6 13]        80  [0. 1. 1. 0. 1.]        37.0\n",
       "7  [37 27 39 14 25]  [18  7 15  4 13]        35  [0. 0. 0. 0. 1.]        13.0\n",
       "8  [ 1 48  4 23 39]  [ 9  4 10 16 12]        51  [1. 0. 1. 1. 0.]        35.0\n",
       "9  [ 4  3 22  9 32]  [14  6  3 17  8]        53  [1. 1. 0. 1. 1.]        45.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dq9VpZh2r2A"
   },
   "source": [
    "**Preprocessing Step**\n",
    "\n",
    "Typically, the initial step in any project that involves reading and handling data is data preprocessing and cleansing.\n",
    "\n",
    "In our dataset, we expect the entries in the \"Weights,\" \"Prices,\" and \"Best Picks\" columns to be in the form of arrays of floats or integers, like this: [45, 40, 42, 38, 10]\n",
    "\n",
    "However, when you read each entry using pandas, they will be in a form of a string: \"[45 40 42 38 10]\"\n",
    "\n",
    "So we need to convert these strings into \"arrays of floats or integers.\" You can utilize the function provided below for this purpose:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "BmUtgrBchaOz"
   },
   "outputs": [],
   "source": [
    "def string_to_list(string):\n",
    "\n",
    "  string_list = string.strip('[]').split()\n",
    "\n",
    "  float_list = [float(element) for element in string_list]\n",
    "\n",
    "  return float_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CP1nkMb27A4n"
   },
   "source": [
    "Furthermore, it's possible that certain rows in the dataset contain empty values in specific columns. We also aim to eliminate these rows as they do not provide any useful information. We use dropna() function to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "LT_iYgxhhaO0"
   },
   "outputs": [],
   "source": [
    "#Ignore the warning messages.\n",
    "\n",
    "dataset = dataset.dropna()\n",
    "\n",
    "dataset.Weights = dataset.Weights.apply(lambda x : string_to_list(x))\n",
    "dataset.Prices = dataset.Prices.apply(lambda x : string_to_list(x))\n",
    "dataset['Best picks'] = dataset['Best picks'].apply(lambda x : string_to_list(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61go4NeA7gZU"
   },
   "source": [
    "Now it's time to implement the search algorithms. For each algorithm, a template is provided to you. You can modify this template if you want. But first you should try to go look at all the parameters used, as they are all important. You can also define any number of auxiliary functions you want.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ER3-7di7ufy"
   },
   "source": [
    "**4. Generate and Test**\n",
    "\n",
    "This part we will have a exhaustive_search algorithm, and we will use it as a standard to compare other algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "FqN5dVe7haO0"
   },
   "outputs": [],
   "source": [
    "def gen_and_test(data):\n",
    "  weights = data['Weights']\n",
    "  prices = data['Prices']\n",
    "  capacity = data['Capacity']\n",
    "\n",
    "  best_solution_price , best_solution = exhaustive_search(weights, prices, capacity)\n",
    "\n",
    "\n",
    "  return best_solution_price, best_solution\n",
    "\n",
    "def exhaustive_search(weights, values, capacity) : # I misunderstood the function of gen_and_test at first, so I wrote this function to do exhaustive search\n",
    "      n = len(weights) # number of items\n",
    "      best_value = 0 # value of the best combination\n",
    "      best_combination = [] # indices of the best combination\n",
    "\n",
    "    \n",
    "      for r in range(n + 1):\n",
    "        for subset in itertools.combinations(range(n), r): # generate all possible combinations of items\n",
    "            total_weight = sum(weights[i] for i in subset) # compute the total weight of this combination\n",
    "            total_value = sum(values[i] for i in subset)  # compute the total value of this combination\n",
    "            if total_weight <= capacity and total_value > best_value: # if this combination is feasible and better than the best one found so far\n",
    "                best_value = total_value # update the best value\n",
    "                best_combination = subset # update the best combination\n",
    "\n",
    "      return best_value, best_combination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "xQyI_WRShaO0"
   },
   "outputs": [],
   "source": [
    "solutions = []\n",
    "start_time_gen_and_test = time.time()\n",
    "for _, row in dataset.iterrows():\n",
    "    target = row['Best price']\n",
    "    solution, indexes = gen_and_test(row)\n",
    "    solutions.append(1 if target == solution else 0)\n",
    "end_time_gen_and_test = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "yodeAYV3haO0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of best prices found is 1.0\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "print('Accuracy of best prices found is', np.mean(solutions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgYGIJMd-atd"
   },
   "source": [
    "**Your Analysis:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  0.25493407249450684\n"
     ]
    }
   ],
   "source": [
    "print(\"Time taken: \", end_time_gen_and_test - start_time_gen_and_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know the complexity of brute force algorithm for this problem is O(n^2), and We can see it tooks about 0.28 second to execute. It will be impossible to finish if the dataset is much larger. However, it is the only algorithm that can reach 100% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8_ipXOGhaO1"
   },
   "source": [
    "**5. Greedy Search**\n",
    "\n",
    "We will have Greedy Search in this part and see how it goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "bAfwGLDkhaO2"
   },
   "outputs": [],
   "source": [
    "def greedy_by_criterion(weights, prices, capacity, criterion):\n",
    "    \"\"\"\n",
    "    Greedy algorithm for the knapsack problem based on a given criterion.\n",
    "    \n",
    "    Args:\n",
    "    - weights (list): List of item weights.\n",
    "    - prices (list): List of item prices.\n",
    "    - capacity (int): Total capacity of the knapsack.\n",
    "    - criterion (list): Sorted list of items based on the chosen criterion.\n",
    "    \n",
    "    Returns:\n",
    "    - int: Total price of the chosen items.\n",
    "    - list: Binary representation of the chosen items.\n",
    "    \"\"\"\n",
    "    current_weight = 0\n",
    "    current_price = 0\n",
    "    current_solution = []\n",
    "\n",
    "    for idx in criterion:\n",
    "        if current_weight + weights[idx] <= capacity:\n",
    "            current_weight += weights[idx]\n",
    "            current_price += prices[idx]\n",
    "            current_solution.append(idx)\n",
    "    \n",
    "    binary_representation = [0.] * len(prices)\n",
    "    for idx in current_solution:\n",
    "        binary_representation[idx] = 1.\n",
    "\n",
    "    return current_price, binary_representation\n",
    "\n",
    "\n",
    "def greedy(data):\n",
    "    weights = data['Weights']\n",
    "    prices = data['Prices']\n",
    "    capacity = data['Capacity']\n",
    "\n",
    "    # Initialize variables for debugging (so we can comment out any logic of this greedy algorithm to see their impact to the correctness of the algorithm) \n",
    "    price_val, price_sol = 0, [0.] * len(prices)\n",
    "    weight_val, weight_sol = 0, [0.] * len(prices)\n",
    "    pw_ratio_val, pw_ratio_sol = 0, [0.] * len(prices)\n",
    "\n",
    "    # Criteria for sorting\n",
    "    price_sorted_indices = sorted(range(len(prices)), key=lambda k: prices[k], reverse=True) # sort by price in descending order\n",
    "    weight_sorted_indices = sorted(range(len(weights)), key=lambda k: weights[k]) # sort by weight in ascending order\n",
    "    pw_ratio_sorted_indices = sorted(range(len(prices)), key=lambda k: prices[k] / weights[k], reverse=True) # sort by price/weight ratio in descending order\n",
    "\n",
    "    # Apply greedy strategy for each criterion \n",
    "    price_val, price_sol = greedy_by_criterion(weights, prices, capacity, price_sorted_indices)  # run greedy algorithm based on price\n",
    "    weight_val, weight_sol = greedy_by_criterion(weights, prices, capacity, weight_sorted_indices) # run greedy algorithm based on weight\n",
    "    pw_ratio_val, pw_ratio_sol = greedy_by_criterion(weights, prices, capacity, pw_ratio_sorted_indices) # run greedy algorithm based on price/weight ratio\n",
    "\n",
    "    # Return the best solution among the three strategies\n",
    "    if price_val >= weight_val and price_val >= pw_ratio_val:\n",
    "        return price_val, price_sol\n",
    "    elif weight_val >= price_val and weight_val >= pw_ratio_val:\n",
    "        return weight_val, weight_sol\n",
    "    else:\n",
    "        return pw_ratio_val, pw_ratio_sol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "QeS54aqAhwhU"
   },
   "outputs": [],
   "source": [
    "solutions_greedy = []\n",
    "start_time_greedy = time.time()\n",
    "for _, row in dataset.iterrows():\n",
    "    target = row['Best price']\n",
    "    solution, indexes = greedy(row)\n",
    "    solutions_greedy.append(1 if target == solution else 0)\n",
    "end_time_greedy = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "xWqCDMs-h0SX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy Accuracy is 0.9901811924283834\n"
     ]
    }
   ],
   "source": [
    "print(\"Greedy Accuracy is\", np.mean(solutions_greedy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  0.1490631103515625\n"
     ]
    }
   ],
   "source": [
    "print(\"Time taken: \", end_time_greedy - start_time_greedy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0DKep6e5-nuz"
   },
   "source": [
    "**Your Analysis:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XGBWQqlK-lra"
   },
   "source": [
    "While addressing this specific knapsack problem, I employed three distinct greedy strategies: prioritizing by highest price, by least weight, and by the price-to-weight ratio. By integrating these three strategies, we achieved an accuracy of approximately 99% with an execution time around 0.55 seconds. This is significantly faster than exhaustive search while maintaining high precision.\n",
    "\n",
    "Diving deeper into the contribution of each strategy, we observe:\n",
    "\n",
    "- **By Highest Price**: When employed exclusively, this emerges as the most effective strategy among the trio with an accuracy of 90.67%.\n",
    "- **By Price-to-Weight Ratio**: Used in isolation, this strategy records an accuracy of 83.42%. While not as effective as the highest price strategy, it remains a relatively potent method.\n",
    "- **By Least Weight**: Using only this approach yields an accuracy of 51.10%. Thus, this strategy seems to have a relatively lower contribution to the dataset, adding about 1% to the accuracy when combined with others.\n",
    "\n",
    "In conclusion, the greedy strategy offers a method balancing time and accuracy. However, for this specific dataset, the strategy prioritizing the least weight appears to be redundant.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PtDW2ja3R93S"
   },
   "source": [
    "**6. Simulated Annealing**\n",
    "\n",
    "We are going to implement Simulated Annealing algorithm in this part, and see its performance and behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "7rFhuXedSF_3"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "def greedy_initial_solution(data):\n",
    "    \"\"\"Get the initial solution using the greedy strategy based on price.\"\"\"\n",
    "    weights = data['Weights']\n",
    "    prices = data['Prices']\n",
    "    capacity = data['Capacity']\n",
    "    \n",
    "    # Sort items based on price, in descending order\n",
    "    price_sorted_indices = sorted(range(len(prices)), key=lambda k: prices[k], reverse=True)\n",
    "    \n",
    "    # Initialize solutions results\n",
    "    total_weight = 0\n",
    "    total_price = 0\n",
    "    solution = [0] * len(weights)  \n",
    "    \n",
    "    for idx in price_sorted_indices:\n",
    "        if total_weight + weights[idx] <= capacity:\n",
    "            total_weight += weights[idx]\n",
    "            total_price += prices[idx]\n",
    "            solution[idx] = 1\n",
    "    \n",
    "    return solution, total_price\n",
    "\n",
    "def energy(solution, weights, prices, capacity):\n",
    "    \"\"\"Compute the energy (fitness) of a solution.\"\"\"\n",
    "    total_weight = sum([w * s for w, s in zip(weights, solution)])\n",
    "    total_price = sum([p * s for p, s in zip(prices, solution)])\n",
    "\n",
    "    # If solution exceeds capacity, return 0\n",
    "    if total_weight > capacity:\n",
    "        return 0\n",
    "    return total_price\n",
    "\n",
    "def accept(deltaE, T):\n",
    "    \"\"\"Acceptance function.\"\"\"\n",
    "    if deltaE > 0:\n",
    "        return True\n",
    "    else:\n",
    "        r = random.random()\n",
    "        return r < math.exp(deltaE / T)\n",
    "    \n",
    "def generate_new_solution_based_on_PWratio(solution, weights, prices, capacity):\n",
    "    \"\"\"\n",
    "    Generate a new solution by considering price-to-weight ratio and introducing some randomness.\n",
    "    \"\"\"\n",
    "    # Copy the current solution\n",
    "    new_solution = solution.copy()\n",
    "    \n",
    "    # Randomly select an item from the current solution\n",
    "    selected_items = [i for i, val in enumerate(solution) if val == 1]\n",
    "    if not selected_items:\n",
    "        return solution\n",
    "    item_to_remove = random.choice(selected_items)\n",
    "    \n",
    "    # Randomly select an item not in the current solution\n",
    "    unselected_items = [i for i, val in enumerate(solution) if val == 0]\n",
    "    if not unselected_items:\n",
    "        return new_solution\n",
    "    item_to_add = random.choice(unselected_items)\n",
    "    \n",
    "    # Compute the value-to-weight ratios\n",
    "    ratio_old = prices[item_to_remove] / weights[item_to_remove]\n",
    "    ratio_new = prices[item_to_add] / weights[item_to_add]\n",
    "    \n",
    "    # Replace the item if the new item has a better ratio or based on a probability\n",
    "    if ratio_new > ratio_old or random.random() < 0.2:\n",
    "        new_solution[item_to_remove] = 0\n",
    "        new_solution[item_to_add] = 1\n",
    "    \n",
    "    return new_solution\n",
    "\n",
    "def generate_new_solution_based_on_temperature(solution, T):\n",
    "    \"\"\"Generate a new candidate solution by flipping multiple bits based on temperature.\"\"\"\n",
    "    # Max number of bits we can flip\n",
    "    max_bits_to_flip = len(solution)\n",
    "    \n",
    "    # Dynamically determine the number of bits to flip based on temperature\n",
    "    # When T is high, we can flip more bits. As T reduces, the number of bits we flip reduces.\n",
    "    num_bits_to_flip = int(T * max_bits_to_flip)\n",
    "    \n",
    "    # If num_bits_to_flip becomes 0, set it to 1 to ensure we flip at least one bit\n",
    "    num_bits_to_flip = max(1, num_bits_to_flip)\n",
    "    \n",
    "    x_new = solution.copy()\n",
    "    \n",
    "    # Randomly choose bits to flip\n",
    "    indices_to_flip = random.sample(range(len(solution)), num_bits_to_flip)\n",
    "    \n",
    "    for idx in indices_to_flip:\n",
    "        x_new[idx] = 1 - x_new[idx]\n",
    "    \n",
    "    return x_new\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def simulated_annealing(data, N , initial_temperature, cooling_rate):\n",
    "    \"\"\"Simulated Annealing for the Knapsack Problem.\"\"\"\n",
    "    weights = data['Weights']\n",
    "    prices = data['Prices']\n",
    "    capacity = data['Capacity']\n",
    "    Tmin = 0.05  # Define a minimum temperature for termination\n",
    "    \" The value minimun temperature is really important. We test it by 0.05, 0.01, 0.001 , and found that 0.05 is the best by balancing the run time and accuary.\"\n",
    "    Eth = 0  # Energy threshold\n",
    "    \n",
    "    T = initial_temperature\n",
    "    # Using greedy strategy to get the initial solution\n",
    "    X, E = greedy_initial_solution(data)\n",
    "    \n",
    "    while T > Tmin and E > Eth:\n",
    "        \n",
    "        # Generate a new candidate solution by using price-to-weight ratio\n",
    "        # it is bad, cause its limited solution space/Preferences for local optimization/lack of randomness\n",
    "        # x_new = generate_new_solution_based_on_PWratio(X, weights, prices, capacity)\n",
    "\n",
    "        # Generate a new candidate solution by flipping multiple random bits\n",
    "        # it is better than the previous one, cause it has more randomness, larger search space, can jump out of local optimum at \n",
    "        # high temperature\n",
    "        x_new = generate_new_solution_based_on_temperature(X, T)\n",
    "        \n",
    "        E_new = energy(x_new, weights, prices, capacity)\n",
    "        deltaE = E_new - E\n",
    "        \n",
    "        # If the new solution is better or accepted by the Accept function\n",
    "        if accept(deltaE, T):\n",
    "            X = x_new\n",
    "            E = E_new\n",
    "            \n",
    "        # Reduce the temperature\n",
    "        T = T * cooling_rate\n",
    "    \n",
    "    return E, X\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "mAWQLNsESNIZ"
   },
   "outputs": [],
   "source": [
    "solutions_sa = []\n",
    "solution_list = []\n",
    "for _, row in dataset.iterrows():\n",
    "    target = row['Best price']\n",
    "    solution, indexes = simulated_annealing(row, N = 10, initial_temperature=1, cooling_rate=0.95)\n",
    "    solutions_sa.append(1 if target == solution else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "jUdWEABkhkih"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated Annealing Accuracy is 0.9464520700475757\n"
     ]
    }
   ],
   "source": [
    "print(\"Simulated Annealing Accuracy is\", np.mean(solutions_sa))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvvpYOOr-qqr"
   },
   "source": [
    "**Your Analysis:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0QXt7Ys-rCc"
   },
   "source": [
    "### Analysis\n",
    "In the Simulated Annealing algorithm, the strategy for generating new candidate solutions and the value of the minimum temperature play critical roles in determining the efficiency and effectiveness of the search process. We compared two distinct strategies for generating new solutions in the context of the Knapsack Problem:\n",
    "\n",
    "1. Price-to-Weight Ratio-Based Strategy: This strategy followed the idea of prioritizing items based on their price-to-weight ratio. By swapping items with differing ratios, this method aimed to improve the quality of the solution.\n",
    "\n",
    "2. Multiple Bit-Flipping Strategy: This approach introduced more randomness into the generation of new candidates. By flipping multiple bits based on the current temperature, the algorithm could explore a wider range of solutions, especially during the early stages when the temperature was high.\n",
    "\n",
    "### Findings:\n",
    "- While the Price-to-Weight Ratio-Based Strategy is intuitive, it exhibited limited exploration capabilities. This often led the algorithm to get trapped in local optima. By predominantly focusing on the value-to-weight ratio, it potentially overlooked other promising regions of the solution space. As a result, the accuracy of the algorithm was slightly lower than that of the Greedy Search, which only used the highest price strategy, even though we employed it as the starting solution.\n",
    "\n",
    "- In contrast, the Multiple Bit-Flipping Strategy provided broader exploration potential. Its inherent randomness allowed the algorithm to escape local optima, leading to a more diverse set of solutions. With this strategy, there was a noticeable improvement in runtime (from 14.5s to 11.7s) and a slight increase in accuracy (from 0.89 to 0.94).\n",
    "\n",
    "- The value of the minimum temperature also played a crucial role in the algorithm's performance. If set too high, the algorithm risked getting trapped in local optima. However, if set too low, the runtime dramatically increased without a commensurate rise in accuracy. In our experiments, we found the best performance when the minimum temperature was set to 0.05, balancing runtime (around 11.7s) and accuracy (around 0.94). Reducing the minimum temperature to 0.01 led to a marginal accuracy increase of 0.005 but increased runtime to 16.7s. Notably, setting it to 0.001 almost doubled the runtime to 23.8s without a significant accuracy boost.\n",
    "\n",
    "### Conclusion:\n",
    "Both the choice of new solution generation strategy and the value of minimum temperature are crucial in Simulated Annealing. While domain-specific knowledge, like the value-to-weight ratio in the Knapsack Problem, can be beneficial, introducing elements of randomness and broader exploration, as seen with the Multiple Bit-Flipping strategy, can significantly enhance the algorithm's performance. Experimenting with and adjusting these strategies based on the specific problem and dataset is key to harnessing the full potential of Simulated Annealing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RHYjBUvVhtGV"
   },
   "source": [
    "**7. Genetic Algorithm**\n",
    "\n",
    "We will implement Genetic Algorithm in this part, and see its performance and behavior and compare it to other algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "5kGKKUN8iP30"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def calculate_fitness(ind, data):\n",
    "    weights = data['Weights']\n",
    "    prices = data['Prices']\n",
    "    capacity = data['Capacity']\n",
    "    \"\"\"Calculate the fitness of an individual.\"\"\"\n",
    "    total_weight = sum([w * s for w, s in zip(weights, ind)])\n",
    "    total_price = sum([p * s for p, s in zip(prices, ind)])\n",
    "    \n",
    "    # If solution exceeds capacity, return 0\n",
    "    if total_weight > capacity:\n",
    "        return 0\n",
    "    return total_price\n",
    "\n",
    "def select_next_generation(population, offspring, population_size,data):\n",
    "    \"\"\"\n",
    "    Selects the next generation from the current population and offspring.\n",
    "\n",
    "    :param population: The current population.\n",
    "    :param offspring: The offspring generated from crossover and mutation.\n",
    "    :param population_size: The fixed size of the population.\n",
    "    :return: The next generation.\n",
    "    \"\"\"\n",
    "    # Combine the population and offspring\n",
    "    combined = population + offspring\n",
    "    \n",
    "    # Sort the combined list based on fitness (assuming higher is better)\n",
    "    sorted_combined = sorted(combined, key=lambda individual:calculate_fitness(individual,data), reverse=True)\n",
    "    \n",
    "    # Select the top 'population_size' individuals\n",
    "    next_generation = sorted_combined[:population_size]\n",
    "    \n",
    "    return next_generation\n",
    "\n",
    " \n",
    "\n",
    "def crossover(parent1, parent2, cross_rate):\n",
    "  # Determine the length of the parents\n",
    "    length = len(parent1)\n",
    "    \n",
    "    # Initialize children as the parents\n",
    "    child1 = parent1.copy()\n",
    "    child2 = parent2.copy()\n",
    "    \n",
    "    # Check if crossover should occur\n",
    "    if random.random() < cross_rate:\n",
    "        # Select a crossover point randomly\n",
    "        cross_point = random.randint(0, length - 1)\n",
    "        \n",
    "        # Swap genes after the crossover point\n",
    "        for i in range(cross_point, length):\n",
    "            child1[i], child2[i] = child2[i], child1[i]\n",
    "\n",
    "    return child1, child2\n",
    "\n",
    "def mutation(child, mut_rate):\n",
    "  return [child[i] if random.random() > mut_rate else 1-child[i] for i in range(len(child))]\n",
    "\n",
    "def initialize_population(population_size, num_items):\n",
    "    \"\"\"\n",
    "    Initializes a population for the knapsack problem.\n",
    "    \"\"\"\n",
    "    population = []\n",
    "    for _ in range(population_size):\n",
    "        individual = [random.choice([0, 1]) for _ in range(num_items)]  # 直接使用整数列表\n",
    "        population.append(individual)\n",
    "    return population\n",
    "\n",
    "def tournament_selection(population, k, num_winners,data):\n",
    "    \"\"\"\n",
    "    Selects a subset of the population using tournament selection.\n",
    "\n",
    "    :param population: The entire population.\n",
    "    :param k: Number of individuals to compete in each tournament.\n",
    "    :param num_winners: Total number of winners (parents) to select. \n",
    "    :return: A subset of the population.\n",
    "    \"\"\"\n",
    "    winners = []\n",
    "    for _ in range(num_winners):\n",
    "        competitors = random.sample(population, k)\n",
    "        winner = max(competitors, key=lambda individual: calculate_fitness(individual,data))\n",
    "        winners.append(winner)\n",
    "\n",
    "    return winners\n",
    "\n",
    "\n",
    "def genetic_algorithm(data, population_size=50, num_generations=50, mut_rate=0.1, cross_rate=0.7, tournament_size=5):\n",
    "    initialized_population = initialize_population(population_size, 5)\n",
    "    weights = data['Weights']\n",
    "    prices = data['Prices']\n",
    "    capacity = data['Capacity']\n",
    "\n",
    "    best_solution_price = 0\n",
    "    best_solution = []\n",
    "    num_crossover = int(cross_rate * population_size) // 2\n",
    "    num_parents = 2 * num_crossover\n",
    "\n",
    "    for _ in range(num_generations): \n",
    "        child_list = []\n",
    "        elite_elements = tournament_selection(initialized_population, tournament_size, num_parents,data)\n",
    "        \n",
    "        for _ in range(num_crossover): \n",
    "            parent1 = elite_elements.pop(random.choice(range(len(elite_elements))))\n",
    "            parent2 = elite_elements.pop(random.choice(range(len(elite_elements))))\n",
    "            new_child1, new_child2 = crossover(parent1, parent2, cross_rate)\n",
    "            child_list.append(mutation(new_child1, mut_rate))\n",
    "            child_list.append(mutation(new_child2, mut_rate))\n",
    "        \n",
    "        initialized_population = select_next_generation(initialized_population, child_list, population_size,data)\n",
    "        \n",
    "        # 检查是否找到更好的解决方案\n",
    "        for individual in initialized_population:\n",
    "            fitness = calculate_fitness(individual, data)\n",
    "            if fitness > best_solution_price :\n",
    "                best_solution_price = fitness\n",
    "                best_solution = individual\n",
    "\n",
    "    return best_solution_price, best_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "5b4hBtUijZzg"
   },
   "outputs": [],
   "source": [
    "solutions_ga = []\n",
    "for _, row in dataset.iterrows():\n",
    "    target = row['Best price']\n",
    "    solution, indexes = genetic_algorithm(row, population_size = 25, num_generations = 25, mut_rate = 0.15, cross_rate = 0.6, tournament_size = 5)\n",
    "    solutions_ga.append(1 if target == solution else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "hJ3ceIHSs-W-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genetic Algorithm Accuracy is 0.9888652697641461\n"
     ]
    }
   ],
   "source": [
    "print(\"Genetic Algorithm Accuracy is\", np.mean(solutions_ga))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yn8KLah-xGF"
   },
   "source": [
    "**Your Analysis:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekb0LOgF-xUN"
   },
   "source": [
    "------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NdO_H-4t-6mg"
   },
   "source": [
    "**8. Comparative Study**\n",
    "\n",
    "description  +  tables/figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ypp7TpkAIUe"
   },
   "source": [
    "--------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Ikmq-si_23Y"
   },
   "source": [
    "**9. Conclusion**\n",
    "\n",
    "Comment on the empirical study, its results, and give ideas for future work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41s8gvCNABDy"
   },
   "source": [
    "--------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PtbOgI1q_9a0"
   },
   "source": [
    "**10 References**\n",
    "\n",
    "Make sure you provide references to ALL sources used (articles, code, algorithms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zF9cuDJqF75q"
   },
   "source": [
    "**Hint:** To share a link to your colab notebook, click on \"share\" on the top right. Then, under *General access* , change *Restricted* to \"Anyone with the link\"."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
